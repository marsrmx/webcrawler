# Web crawler

Simple web crawler to download the files from [CONAGUA](https://www.gob.mx/conagua/articulos/calidad-del-agua?idiom=es) and locally store them. The extensions available to download are `xlsb, xlsx and pdf`. 

This data set is going to be use for the SocialData Challenge 3.0

Team - _Agua Artificial_

### Resources

https://www.digitalocean.com/community/tutorials/how-to-scrape-web-pages-with-beautiful-soup-and-python-3
https://www.crummy.com/software/BeautifulSoup/bs4/doc/#tag
https://github.com/dhdzmota/web-project/blob/master/your-code/Web%20Scraping%20and%20API.ipynb
https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_csv.html
https://stackoverflow.com/questions/4776924/how-to-safely-get-the-file-extension-from-a-url
